# 安装环境(Windows和Linux:课件中我整理理了了图⽂文安装教程，如果遇到问题可以⾃自⾏行行百度，难度 不不⼤大，实在不不⾏行行也可以问我，这⾥里里就不不演示步骤了了)
## 安装ES
### 安装六字箴⾔言:
-  JDK->依赖
-  下载->elastic.co
-  启动->./elasticsearch -d
-  验证->http://localhost:9200/
-  开发模式和⽣生产模式
-  开发模式:默认配置(未配置发现设置)，⽤用于学习阶段 -  ⽣生产模式:会触发ES的引导检查，学习阶段不不建议修改集 群相关的配置。
##  安装Kibana(从版本- - 0开始，Kibana仅⽀支持64位操作系统。)
-  下载:http://elastic.co
-  启动:依然是开箱即⽤ 
Linux: bin/kibana 不想看不断打印日志就：  
          `bin/kibana 1>/dev/null`
Windows:.\kibana.bat
-  验证:localhost:5601 注意⚠️：要用Chrome打开，Sarfari会卡住！！！！！！
    http://192.168.1.28:5601/app/dev_tools#/console
##  安装Head插件(选装):
-  介绍:提供可视化的操作⻚页⾯面对ElasticSearch搜索引擎进⾏行行各 种设置和数据检索功能，可以很直观的查看集群的健康状况，索引 分配情况，还可以管理理索引和集群以及提供⽅方便便快捷的搜索功能等 等。
-  下载:https://github.com/mobz/elasticsearch-head同时课件中 也提供了了安装包。
-  安装:依赖于node和grunt管理理⼯工具
-  启动:npm run start
-  验证:http://localhost:9100/  
   参考：https://www.jianshu.com/p/6102cffc96f1, 只不过执行 npm install的时候会出错，用 `npm install  --unsafe-perm` 即可 
- 集群健康值:
##  健康值检查
-  _cat/health
-  _cluster/health
##  健康值状态
-  :所有Primary和Replica均为active，集群健康
-  :⾄至少⼀一个Replica不不可⽤用，但是所有Primary均为 active，数据仍然是可以保证完整性的。
-  Red:⾄至少有⼀一个Primary为不不可⽤用状态，数据不不完整，集群不不 可⽤用。
- 基于XX系统的CRUD - 创建索引:PUT /product?pretty - 查询索引:GET _cat/indices?v
 
 Green
 Yellow
 - 删除索引:DELETE /product?pretty - 插⼊入数据:
PUT /index/_doc/id {
Json数据 }
- 更更新数据
-  全量量替换
-  指定字段更更新 - 删除数据 DELETE /index/type/id
ES分布式⽂文档系统 - ES如何实现⾼高可⽤用(⽣生产环境均为⼀一台机器器⼀一个节点)
##  ES在分配单个索引的分⽚片时会将每个分⽚片尽可能分配到更更多的节 点上。但是，实际情况取决于集群拥有的分⽚片和索引的数量量以及它们的 ⼤大⼩小，不不⼀一定总是能均匀地分布。
##  ES不不允许Primary和它的Replica放在同⼀一个节点中，并且同⼀一个节 点不不接受完全相同的两个Replica
##  同⼀一个节点允许多个索引的分⽚片同时存在。 

## 容错机制
###  啥叫容错?
-  傻X的代码你能看懂，⽜牛X的代码你也能看懂
-  只能看懂⾃自⼰己的代码，容错性低
-  PS:各种情况(⽀支持的情况越多，容错性越好)下，都能保证 work 正常运⾏行行
-  换到咱们ES上就是，就是在局部出错异常的情况下，保证服务 正常运⾏行行并且有⾃自⾏行行恢复能⼒力力。主挂了之后集群会自动Raft选主，然后继续提供服务。原来的主再次启动，
   则不会抢回主的地位，且整个集群会重新调整分片的分布。意外亲测有效
##  ES-node - 
-  Master:主节点，每个集群都有且只有⼀一个 a. 尽量量避免Master节点 node.data = true
-  voting:投票节点
a. Node.voting_only = true(仅
)。
-  coordinating:协调节点
每⼀一个节点都隐式的是⼀一个协调节点，如果同时设置了了 data.master = false和data.data=false，那么此节点将成为仅协 调节点。
-  Master-eligible node(候选节点):
-  Data node(数据节点):
-  Ingest node:
-  Machine learning node(机器器学习节点):
  data.master = true，也不不会参选, 但是仍然可以作为数据节
投票节点，即使配置了了
  点

 -  两个配置:node.master和node.data
-  node.master = true node.data = true 这是ES节点默认配置，既作为候选节点⼜又作为数据节点，这样 的节点⼀一旦被选举为Master，压⼒力力是⽐比较⼤大的，通常来说 Master节点应该只承担较为轻量量级的任务，⽐比如创建删除索 引，分⽚片均衡等。
-  node.master = true node.data = false 只作为候选节点，不不作为数据节点，可参选Master节点，当选 后成为真正的Master节点。
-  node.master = false node.data = false 既不不当候选节点，也不不作为数据节点，那就是仅协调节点，负 责负载均衡
-  node.master=false node.data=true 不不作为候选节点，但是作为数据节点，这样的节点主要负责数 据存储和查询服务。
##  图解容错机制
-  第⼀一步:Master选举(假如宕机节点是Master)
-  脑裂:可能会产⽣生多个Master节点
-  解决:discovery.zen.minimum_master_nodes=N/2+1
-  第⼆二步:Replica容错，新的(或者原有)Master节点会将丢失
的Primary对应的某个副本提升为Primary
-  第三步:Master节点会尝试重启故障机
-  第四步:数据同步，Master会将宕机期间丢失的数据同步到重 启机器器对应的分⽚片上去
3、总结(如何提⾼高ES分布式系统的可⽤用性以及性能最⼤大化): ## 每台节点的Shard数量量越少，每个shard分配的CPU、内存和IO资源 越多，单个Shard的性能越好，当⼀一台机器器⼀一个Shard时，单个Shard性能 最好。 ## 稳定的Master节点对于群集健康⾮非常重要!理理论上讲，应该尽可能的 减轻Master节点的压⼒力力，分⽚片数量量越多，Master节点维护管理理shard的任务 越重，并且节点可能就要承担更更多的数据转发任务，可增加“仅协调”节点来 缓解Master节点和Data节点的压⼒力力，但是
。 ## 反过来说，如果相同资源分配相同的前提下，shard数量量越少，单个 shard的体积越⼤大，查询性能越低，速度越慢，这个取舍应根据实际集群状 况和结合应⽤用场景等因素综合考虑。 ## 数据节点和Master节点⼀一定要分开，集群规模越⼤大，这样做的意义也 就越⼤大。 ## 数据节点处理理与数据相关的操作，例例如CRUD，搜索和聚合。这些操 作是I / O，内存和CPU密集型的，所以他们需要更更⾼高配置的服务器器以及更更
  会增加整个集群的负担，因为选择的主节点必须等待每个节点的集群状态
在集群中添加过多的仅协调节点
  更更新确认

⾼高的带宽，并且集群的性能冗余⾮非常重要。
## 由于仅投票节不不参与Master竞选，所以和真正的Master节点相⽐比，它 需要的内存和CPU较少。但是，所有候选节点以及仅投票节点都可能是数 据节点，所以他们都需要快速稳定低延迟的⽹网络。 ## ⾼高可⽤用性(HA)群集⾄至少需要三个主节点，其中⾄至少两个不不是仅投 票节点。即使其中⼀一个节点发⽣生故障，这样的群集也将能够选举⼀一个主节 点。⽣生产环境最好设置3台仅Master候选节点(node.master = true node.data = true)
## 为确保群集仍然可⽤用，集群不不能同时停⽌止投票配置中的⼀一半或更更多 节点。只要有⼀一半以上的投票节点可⽤用，群集仍可以正常⼯工作。这意味 着，如果存在三个或四个主节点合格的节点，则群集可以容忍其中⼀一个节 点不不可⽤用。如果有两个或更更少的主机资格节点，则它们必须都保持可⽤用